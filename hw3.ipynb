{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from skimage import transform as tf\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "from LFWDataset import LFWDataset\n",
    "from SiameseNet import SiameseNet\n",
    "from ContrastiveLoss import ContrastiveLoss\n",
    "from augmentation import *\n",
    "# from p1a import data_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def show(img, filename=None, save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    if save and filename is not None:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "def show_plot(iteration,loss, filename='loss.png', save=False):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = LFWDataset(train=True,\n",
    "                      transform=transforms.Compose([augmentation, transforms.Scale((128,128)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ]))\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_dataloader = DataLoader(trainset,\n",
    "#                         shuffle=True,\n",
    "#                         num_workers=2,\n",
    "#                         batch_size=8)\n",
    "# dataiter = iter(vis_dataloader)\n",
    "\n",
    "# example_batch = next(dataiter)\n",
    "# concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
    "\n",
    "# show(torchvision.utils.make_grid(concatenated))\n",
    "# print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNet(p1b=True).cuda()\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = ContrastiveLoss()\n",
    "learning_rate = 1e-6\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseNet (\n",
      "  (cnn): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU (inplace)\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (5): ReLU (inplace)\n",
      "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU (inplace)\n",
      "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU (inplace)\n",
      "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (fc1): Sequential (\n",
      "    (0): Linear (131072 -> 1024)\n",
      "    (1): ReLU (inplace)\n",
      "    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (fc2): Sequential (\n",
      "    (0): Linear (2048 -> 1)\n",
      "    (1): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 0\n",
      " Current loss 344.980133057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/home/zdavidli/.local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zdavidli/.local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "  File \"/home/zdavidli/.local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 109, in default_collate\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"LFWDataset.py\", line 48, in __getitem__\n",
      "    im1 = self.transform(im1)\n",
      "  File \"/home/zdavidli/.local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 91, in default_collate\n",
      "  File \"/home/zdavidli/.local/lib/python2.7/site-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "    img = t(img)\n",
      "  File \"/home/zdavidli/.local/lib/python2.7/site-packages/torch/functional.py\", line 66, in stack\n",
      "  File \"/home/zdavidli/.local/lib/python2.7/site-packages/torchvision/transforms.py\", line 199, in __call__\n",
      "    return img.resize(self.size, self.interpolation)\n",
      "  File \"/home/zdavidli/.local/lib/python2.7/site-packages/PIL/Image.py\", line 1745, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "KeyboardInterrupt\n",
      "    return torch.cat(inputs, dim, out=out)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d96c48a4829a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#         loss = criterion(output, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zdavidli/.local/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zdavidli/.local/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        img0, img1 , label = data\n",
    "        img0, img1 , label = Variable(img0).cuda(), Variable(img1).cuda() , Variable(label).cuda()\n",
    "#         output = net(img0, img1)\n",
    "        output1, output2 = net(img0,img1)\n",
    "        label = label.unsqueeze(1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         loss = criterion(output, label)\n",
    "        loss = criterion(output1, output2, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i %10 == 0 :\n",
    "            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss.data[0]))\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_plot(counter,loss_history, save=True)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(counter,loss_history)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig('loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"p1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = LFWDataset(test=True,\n",
    "                     transform=transforms.Compose([transforms.Scale((128, 128)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ]))\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('p1b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right=wrong=0.\n",
    "\n",
    "for i, data in enumerate(testloader,0):\n",
    "    img0, img1, label = data    \n",
    "    img0, img1, label = Variable(img0).cuda(), Variable(img1).cuda(), Variable(label).cuda()\n",
    "    \n",
    "    output1, output2 = net(img0,img1)\n",
    "    dist = F.pairwise_distance(output1, output2)\n",
    "    print(dist)\n",
    "    print(label)\n",
    "    for x,y in zip(dist, label):\n",
    "        if (x.data[0]>=11 and y.data[0]==1) or (x.data[0]<11 and y.data[0]==0):\n",
    "            right+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     print(right, wrong)\n",
    "testacc = right/(right+wrong)\n",
    "print(\"Accuracy on test set: {:.2f}\".format(testacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right=wrong=0.\n",
    "\n",
    "for i, data in enumerate(trainloader,0):\n",
    "    img0, img1, label = data    \n",
    "    img0, img1, label = Variable(img0).cuda(), Variable(img1).cuda(), Variable(label).cuda()\n",
    "    \n",
    "    output = net(img0,img1)\n",
    "    for x,y in zip(dist, label):\n",
    "        if (x.data[0]<=11 and y.data[0]==1) or (x.data[0]>11 and y.data[0]==0):\n",
    "            right+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     print(right, wrong)\n",
    "trainacc = right/(right+wrong)\n",
    "print(\"Accuracy on train set: {:.2f}\".format(trainacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.autograd.Variable(torch.randn(3), requires_grad=True)\n",
    "target = torch.autograd.Variable(torch.FloatTensor(3).random_(2))\n",
    "print(input, target)\n",
    "output = loss(m(input), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open(\"lfw/Taufik_Hidayat/Taufik_Hidayat_0001.jpg\")\n",
    "\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_aug(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
